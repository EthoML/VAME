"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5268],{7295:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>t,default:()=>a,frontMatter:()=>i,metadata:()=>o,toc:()=>c});var r=s(4848),l=s(8453);const i={sidebar_label:"rnn_vae",title:"model.rnn_vae"},t=void 0,o={id:"reference/model/rnn_vae",title:"model.rnn_vae",description:"logger\\_config",source:"@site/docs/reference/model/rnn_vae.md",sourceDirName:"reference/model",slug:"/reference/model/rnn_vae",permalink:"/VAME/docs/reference/model/rnn_vae",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"rnn_vae",title:"model.rnn_vae"},sidebar:"docsSidebar",previous:{title:"rnn_model",permalink:"/VAME/docs/reference/model/rnn_model"},next:{title:"pipeline",permalink:"/VAME/docs/reference/pipeline"}},d={},c=[{value:"logger_config",id:"logger_config",level:4},{value:"logger",id:"logger",level:4},{value:"tqdm_to_logger",id:"tqdm_to_logger",level:4},{value:"TENSORBOARD_ENABLED",id:"tensorboard_enabled",level:4},{value:"TENSORBOARD_LOG_FREQUENCY",id:"tensorboard_log_frequency",level:4},{value:"TENSORBOARD_LOG_HISTOGRAMS",id:"tensorboard_log_histograms",level:4},{value:"use_gpu",id:"use_gpu",level:4},{value:"reconstruction_loss",id:"reconstruction_loss",level:4},{value:"future_reconstruction_loss",id:"future_reconstruction_loss",level:4},{value:"cluster_loss",id:"cluster_loss",level:4},{value:"kullback_leibler_loss",id:"kullback_leibler_loss",level:4},{value:"kl_annealing",id:"kl_annealing",level:4},{value:"gaussian",id:"gaussian",level:4},{value:"train",id:"train",level:4},{value:"test",id:"test",level:4},{value:"train_model",id:"train_model",level:4}];function h(e){const n={a:"a",code:"code",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h4,{id:"logger_config",children:"logger_config"}),"\n",(0,r.jsx)(n.h4,{id:"logger",children:"logger"}),"\n",(0,r.jsx)(n.h4,{id:"tqdm_to_logger",children:"tqdm_to_logger"}),"\n",(0,r.jsx)(n.h4,{id:"tensorboard_enabled",children:"TENSORBOARD_ENABLED"}),"\n",(0,r.jsx)(n.h4,{id:"tensorboard_log_frequency",children:"TENSORBOARD_LOG_FREQUENCY"}),"\n",(0,r.jsx)(n.p,{children:"Log every N batches"}),"\n",(0,r.jsx)(n.h4,{id:"tensorboard_log_histograms",children:"TENSORBOARD_LOG_HISTOGRAMS"}),"\n",(0,r.jsx)(n.p,{children:"Set to True to log parameter histograms"}),"\n",(0,r.jsx)(n.h4,{id:"use_gpu",children:"use_gpu"}),"\n",(0,r.jsx)(n.h4,{id:"reconstruction_loss",children:"reconstruction_loss"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def reconstruction_loss(x: torch.Tensor, x_tilde: torch.Tensor,\n                        reduction: str) -> torch.Tensor\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compute the reconstruction loss between input and reconstructed data."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"x"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Input data tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"x_tilde"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Reconstructed data tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"reduction"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Type of reduction for the loss."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"torch.Tensor"}),": Reconstruction loss."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"future_reconstruction_loss",children:"future_reconstruction_loss"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def future_reconstruction_loss(x: torch.Tensor, x_tilde: torch.Tensor,\n                               reduction: str) -> torch.Tensor\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compute the future reconstruction loss between input and predicted future data."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"x"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Input future data tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"x_tilde"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Reconstructed future data tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"reduction"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Type of reduction for the loss."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"torch.Tensor"}),": Future reconstruction loss."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"cluster_loss",children:"cluster_loss"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def cluster_loss(H: torch.Tensor, kloss: int, lmbda: float,\n                 batch_size: int) -> torch.Tensor\n"})}),"\n",(0,r.jsx)(n.p,{children:"Compute the cluster loss."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"H"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Latent representation tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kloss"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Number of clusters."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"lmbda"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Lambda value for the loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"batch_size"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Size of the batch."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"torch.Tensor"}),": Cluster loss."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"kullback_leibler_loss",children:"kullback_leibler_loss"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def kullback_leibler_loss(mu: torch.Tensor,\n                          logvar: torch.Tensor) -> torch.Tensor\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Compute the Kullback-Leibler divergence loss.\nSee Appendix B from VAE paper: Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014 - ",(0,r.jsx)(n.a,{href:"https://arxiv.org/abs/1312.6114",children:"https://arxiv.org/abs/1312.6114"})]}),"\n",(0,r.jsx)(n.p,{children:"Formula: 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"mu"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Mean of the latent distribution."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"logvar"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Log variance of the latent distribution."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"torch.Tensor"}),": Kullback-Leibler divergence loss."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"kl_annealing",children:"kl_annealing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def kl_annealing(epoch: int, kl_start: int, annealtime: int,\n                 function: str) -> float\n"})}),"\n",(0,r.jsx)(n.p,{children:"Anneal the Kullback-Leibler loss to let the model learn first the reconstruction of the data\nbefore the KL loss term gets introduced."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"epoch"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Current epoch number."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kl_start"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Epoch number to start annealing the loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"annealtime"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Annealing time."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"function"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Annealing function type."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"float"}),": Annealed weight value for the loss."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"gaussian",children:"gaussian"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def gaussian(ins: torch.Tensor,\n             is_training: bool,\n             seq_len: int,\n             std_n: float = 0.8) -> torch.Tensor\n"})}),"\n",(0,r.jsx)(n.p,{children:"Add Gaussian noise to the input data."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ins"})," (",(0,r.jsx)(n.code,{children:"torch.Tensor"}),"): Input data tensor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"is_training"})," (",(0,r.jsx)(n.code,{children:"bool"}),"): Whether it is training mode."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"seq_len"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"std_n"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Standard deviation for the Gaussian noise."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"torch.Tensor"}),": Noisy input data tensor."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"train",children:"train"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def train(\n    train_loader: Data.DataLoader,\n    epoch: int,\n    model: nn.Module,\n    optimizer: torch.optim.Optimizer,\n    anneal_function: str,\n    BETA: float,\n    kl_start: int,\n    annealtime: int,\n    seq_len: int,\n    future_decoder: bool,\n    future_steps: int,\n    scheduler: Union[torch.optim.lr_scheduler._LRScheduler, ReduceLROnPlateau,\n                     StepLR],\n    mse_red: str,\n    mse_pred: str,\n    kloss: int,\n    klmbda: float,\n    bsize: int,\n    noise: bool,\n    writer: Optional[SummaryWriter] = None,\n    global_step: int = 0\n) -> Tuple[float, float, float, float, float, float, int]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Train the model."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"train_loader"})," (",(0,r.jsx)(n.code,{children:"DataLoader"}),"): Training data loader."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"epoch"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Current epoch number."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model"})," (",(0,r.jsx)(n.code,{children:"nn.Module"}),"): Model to be trained."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"optimizer"})," (",(0,r.jsx)(n.code,{children:"Optimizer"}),"): Optimizer for training."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"anneal_function"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Annealing function type."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"BETA"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Beta value for the loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kl_start"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Epoch number to start annealing the loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"annealtime"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Annealing time."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"seq_len"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"future_decoder"})," (",(0,r.jsx)(n.code,{children:"bool"}),"): Whether a future decoder is used."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"future_steps"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Number of future steps to predict."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"scheduler"})," (",(0,r.jsx)(n.code,{children:"Union[_LRScheduler, ReduceLROnPlateau]"}),"): Learning rate scheduler."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"mse_red"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Reduction type for MSE reconstruction loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"mse_pred"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Reduction type for MSE prediction loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kloss"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Number of clusters for cluster loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"klmbda"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Lambda value for cluster loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"bsize"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Size of the batch."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"noise"})," (",(0,r.jsx)(n.code,{children:"bool"}),"): Whether to add Gaussian noise to the input."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"writer"})," (",(0,r.jsx)(n.code,{children:"Optional[SummaryWriter]"}),"): TensorBoard writer for logging."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"global_step"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Global step counter for TensorBoard logging."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Tuple[float, float, float, float, float, float, int]"}),": Kullback-Leibler weight, train loss, K-means loss, KL loss,\nMSE loss, future loss, updated global step."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"test",children:"test"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def test(test_loader: Data.DataLoader,\n         model: nn.Module,\n         BETA: float,\n         kl_weight: float,\n         seq_len: int,\n         mse_red: str,\n         kloss: int,\n         klmbda: float,\n         future_decoder: bool,\n         bsize: int,\n         writer: Optional[SummaryWriter] = None,\n         epoch: int = 0) -> Tuple[float, float, float]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Evaluate the model on the test dataset."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"test_loader"})," (",(0,r.jsx)(n.code,{children:"DataLoader"}),"): DataLoader for the test dataset."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model"})," (",(0,r.jsx)(n.code,{children:"nn.Module"}),"): The trained model."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"BETA"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Beta value for the VAE loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kl_weight"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Weighting factor for the KL divergence loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"seq_len"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"mse_red"})," (",(0,r.jsx)(n.code,{children:"str"}),"): Reduction method for the MSE loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kloss"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Loss function for K-means clustering."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"klmbda"})," (",(0,r.jsx)(n.code,{children:"float"}),"): Lambda value for K-means loss."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"future_decoder"})," (",(0,r.jsx)(n.code,{children:"bool"}),"): Flag indicating whether to use a future decoder."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"bsize"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Batch size."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"writer"})," (",(0,r.jsx)(n.code,{children:"Optional[SummaryWriter]"}),"): TensorBoard writer for logging."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"epoch"})," (",(0,r.jsx)(n.code,{children:"int"}),"): Current epoch number."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Tuple[float, float, float]"}),": Tuple containing MSE loss per item, total test loss per item,\nand K-means loss weighted by the kl_weight."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"train_model",children:"train_model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"@save_state(model=TrainModelFunctionSchema)\ndef train_model(config: dict, save_logs: bool = True) -> None\n"})}),"\n",(0,r.jsx)(n.p,{children:'Train Variational Autoencoder using the configuration file values.\nFills in the values in the "train_model" key of the states.json file.\nCreates files at:'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["project_name/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["model/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["best_model/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["snapshots/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"model_name_Project_epoch_0.pkl"}),"\n",(0,r.jsx)(n.li,{children:"..."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"model_name_Project.pkl"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["model_losses/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"fut_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"kl_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"kmeans_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"mse_test_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"mse_train_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"test_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"train_losses_VAME.npy"}),"\n",(0,r.jsx)(n.li,{children:"weight_values_VAME.npy"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"pretrained_model/"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["logs/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["tensorboard/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["model_name/","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"events.out.tfevents..."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"config"})," (",(0,r.jsx)(n.code,{children:"dict"}),"): Configuration dictionary."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"save_logs"})," (",(0,r.jsx)(n.code,{children:"bool, optional"}),"): Whether to save the logs. Default is True."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"None"})}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>o});var r=s(6540);const l={},i=r.createContext(l);function t(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:t(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);