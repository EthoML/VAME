"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4841],{2383:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});var s=i(4848),l=i(8453);const r={sidebar_label:"align_egocentrical",title:"vame.util.align_egocentrical"},o=void 0,t={id:"reference/vame/util/align_egocentrical",title:"vame.util.align_egocentrical",description:"Variational Animal Motion Embedding 0.1 Toolbox",source:"@site/docs/reference/vame/util/align_egocentrical.md",sourceDirName:"reference/vame/util",slug:"/reference/vame/util/align_egocentrical",permalink:"/VAME/docs/reference/vame/util/align_egocentrical",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"align_egocentrical",title:"vame.util.align_egocentrical"},sidebar:"docsSidebar",previous:{title:"states",permalink:"/VAME/docs/reference/vame/schemas/states"},next:{title:"auxiliary",permalink:"/VAME/docs/reference/vame/util/auxiliary"}},c={},d=[{value:"align_mouse",id:"align_mouse",level:4},{value:"play_aligned_video",id:"play_aligned_video",level:4},{value:"alignment",id:"alignment",level:4},{value:"egocentric_alignment",id:"egocentric_alignment",level:4}];function a(e){const n={a:"a",code:"code",em:"em",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Variational Animal Motion Embedding 0.1 Toolbox\n\xa9 K. Luxem & J. K\xfcrsch & P. Bauer, Department of Cellular Neuroscience\nLeibniz Institute for Neurobiology, Magdeburg, Germany"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/LINCellularNeuroscience/VAME",children:"https://github.com/LINCellularNeuroscience/VAME"}),"\nLicensed under GNU General Public License v3.0"]}),"\n",(0,s.jsx)(n.h4,{id:"align_mouse",children:"align_mouse"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def align_mouse(\n    path_to_file: str,\n    filename: str,\n    video_format: str,\n    crop_size: Tuple[int, int],\n    pose_list: List[np.ndarray],\n    pose_ref_index: Tuple[int, int],\n    confidence: float,\n    pose_flip_ref: Tuple[int, int],\n    bg: np.ndarray,\n    frame_count: int,\n    use_video: bool = True,\n    tqdm_stream: TqdmToLogger = None\n) -> Tuple[List[np.ndarray], List[List[np.ndarray]], np.ndarray]\n"})}),"\n",(0,s.jsx)(n.p,{children:"Align the mouse in the video frames."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"path_to_file"})," ",(0,s.jsx)(n.em,{children:"str"})," - Path to the file directory."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"filename"})," ",(0,s.jsx)(n.em,{children:"str"})," - Name of the video file without the format."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"video_format"})," ",(0,s.jsx)(n.em,{children:"str"})," - Format of the video file."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"crop_size"})," ",(0,s.jsx)(n.em,{children:"Tuple[int, int]"})," - Size to crop the video frames."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pose_list"})," ",(0,s.jsx)(n.em,{children:"List[np.ndarray]"})," - List of pose coordinates."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pose_ref_index"})," ",(0,s.jsx)(n.em,{children:"Tuple[int, int]"})," - Pose reference indices."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"confidence"})," ",(0,s.jsx)(n.em,{children:"float"})," - Pose confidence threshold."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pose_flip_ref"})," ",(0,s.jsx)(n.em,{children:"Tuple[int, int]"})," - Reference indices for flipping."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"bg"})," ",(0,s.jsx)(n.em,{children:"np.ndarray"})," - Background image."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"frame_count"})," ",(0,s.jsx)(n.em,{children:"int"})," - Number of frames to align."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"filename"}),"0 ",(0,s.jsx)(n.em,{children:"bool, optional"})," - bool if video should be cropped or DLC points only. Defaults to True."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Returns"}),":"]}),"\n",(0,s.jsx)(n.p,{children:"Tuple[List[np.ndarray], List[List[np.ndarray]], np.ndarray]: List of aligned images, list of aligned DLC points, and time series data."}),"\n",(0,s.jsx)(n.h4,{id:"play_aligned_video",children:"play_aligned_video"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def play_aligned_video(a: List[np.ndarray], n: List[List[np.ndarray]],\n                       frame_count: int) -> None\n"})}),"\n",(0,s.jsx)(n.p,{children:"Play the aligned video."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"a"})," ",(0,s.jsx)(n.em,{children:"List[np.ndarray]"})," - List of aligned images."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"n"})," ",(0,s.jsx)(n.em,{children:"List[List[np.ndarray]]"})," - List of aligned DLC points."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"frame_count"})," ",(0,s.jsx)(n.em,{children:"int"})," - Number of frames in the video."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"alignment",children:"alignment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def alignment(\n        path_to_file: str,\n        filename: str,\n        pose_ref_index: List[int],\n        video_format: str,\n        crop_size: Tuple[int, int],\n        confidence: float,\n        pose_estimation_filetype: PoseEstimationFiletype,\n        path_to_pose_nwb_series_data: str = None,\n        use_video: bool = False,\n        check_video: bool = False,\n        tqdm_stream: TqdmToLogger = None\n) -> Tuple[np.ndarray, List[np.ndarray]]\n"})}),"\n",(0,s.jsx)(n.p,{children:"Perform alignment of egocentric data."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"path_to_file"})," ",(0,s.jsx)(n.em,{children:"str"})," - Path to the file directory."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"filename"})," ",(0,s.jsx)(n.em,{children:"str"})," - Name of the video file without the format."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pose_ref_index"})," ",(0,s.jsx)(n.em,{children:"List[int]"})," - Pose reference indices."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"video_format"})," ",(0,s.jsx)(n.em,{children:"str"})," - Format of the video file."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"crop_size"})," ",(0,s.jsx)(n.em,{children:"Tuple[int, int]"})," - Size to crop the video frames."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"confidence"})," ",(0,s.jsx)(n.em,{children:"float"})," - Pose confidence threshold."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"use_video"})," ",(0,s.jsx)(n.em,{children:"bool, optional"})," - Whether to use video for alignment. Defaults to False."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"check_video"})," ",(0,s.jsx)(n.em,{children:"bool, optional"})," - Whether to check the aligned video. Defaults to False."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Returns"}),":"]}),"\n",(0,s.jsx)(n.p,{children:"Tuple[np.ndarray, List[np.ndarray]]: Aligned time series data and list of aligned frames."}),"\n",(0,s.jsx)(n.h4,{id:"egocentric_alignment",children:"egocentric_alignment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"@save_state(model=EgocentricAlignmentFunctionSchema)\ndef egocentric_alignment(config: str,\n                         pose_ref_index: list = [5, 6],\n                         crop_size: tuple = (300, 300),\n                         use_video: bool = False,\n                         video_format: str = '.mp4',\n                         check_video: bool = False,\n                         save_logs: bool = False) -> None\n"})}),"\n",(0,s.jsx)(n.p,{children:"Aligns egocentric data for VAME training"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Arguments"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"config"})," ",(0,s.jsx)(n.em,{children:"str"})," - Path for the project config file."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pose_ref_index"})," ",(0,s.jsx)(n.em,{children:"list, optional"})," - Pose reference index to be used to align. Defaults to [5,6]."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"crop_size"})," ",(0,s.jsx)(n.em,{children:"tuple, optional"})," - Size to crop the video. Defaults to (300,300)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"use_video"})," ",(0,s.jsx)(n.em,{children:"bool, optional"})," - Weather to use video to do the post alignment. Defaults to False. # TODO check what to put in this docstring"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"video_format"})," ",(0,s.jsx)(n.em,{children:"str, optional"})," - Video format, can be .mp4 or .avi. Defaults to '.mp4'."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"check_video"})," ",(0,s.jsx)(n.em,{children:"bool, optional"})," - Weather to check the video. Defaults to False."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Raises"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ValueError"})," - If the config.yaml indicates that the data is not egocentric."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>t});var s=i(6540);const l={},r=s.createContext(l);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);